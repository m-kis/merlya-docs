{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Merlya","text":"<p>AI-powered infrastructure assistant for DevOps and SRE teams.</p> <p>Merlya is a command-line tool that combines the power of large language models with practical infrastructure management capabilities. It helps you manage SSH connections, execute commands across multiple servers, and automate routine tasks using natural language.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p> Natural Language Interface</p> <p>Interact with your infrastructure using plain English. No need to memorize complex command syntax.</p> </li> <li> <p> SSH Management</p> <p>Connect to servers, execute commands, and manage connections with built-in pooling and retry logic.</p> </li> <li> <p> Multiple LLM Providers</p> <p>Support for OpenAI, Anthropic, Ollama, and more. Use cloud or local models.</p> </li> <li> <p> Secure by Design</p> <p>Credentials stored in system keyring. No secrets in config files.</p> </li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code># Install Merlya\npip install merlya\n\n# Configure your LLM provider\nmerlya config set llm.provider openai\nmerlya config set llm.api_key sk-...\n\n# Start chatting with your infrastructure\nmerlya chat\n</code></pre> <pre><code>You: Connect to my web server and check disk usage\nMerlya: I'll connect to web-server-01 and check the disk usage.\n\n&gt; ssh web-server-01 \"df -h\"\n\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/sda1       100G   45G   55G  45% /\n\nThe disk usage is at 45%. You have 55GB available.\n</code></pre>"},{"location":"#why-merlya","title":"Why Merlya?","text":"<ul> <li>Speed: Execute complex operations with simple commands</li> <li>Safety: Review commands before execution, secure credential storage</li> <li>Flexibility: Works with any LLM provider, local or cloud</li> <li>Extensibility: Plugin system for custom tools and integrations</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to get started? Check out the Installation Guide to set up Merlya in minutes.</p> <p>Get Started  View on GitHub </p>"},{"location":"architecture/decisions/","title":"Architecture Decisions","text":"<p>Key architectural decisions and their rationale.</p>"},{"location":"architecture/decisions/#overview","title":"Overview","text":"<p>Merlya is built on a modular architecture designed for extensibility, security, and ease of use.</p> <pre><code>graph TB\n    subgraph \"User Interface\"\n        CLI[CLI / REPL]\n    end\n\n    subgraph \"Core\"\n        Router[Intent Router]\n        Context[Context Manager]\n        Agent[PydanticAI Agent]\n    end\n\n    subgraph \"Tools\"\n        SSH[SSH Tools]\n        System[System Tools]\n        Security[Security Tools]\n    end\n\n    subgraph \"Providers\"\n        OpenAI[OpenAI]\n        Anthropic[Anthropic]\n        Ollama[Ollama]\n    end\n\n    CLI --&gt; Router\n    Router --&gt; Agent\n    Agent --&gt; Context\n    Agent --&gt; SSH\n    Agent --&gt; System\n    Agent --&gt; Security\n    Agent --&gt; OpenAI\n    Agent --&gt; Anthropic\n    Agent --&gt; Ollama</code></pre>"},{"location":"architecture/decisions/#adr-001-pydanticai-for-agent-framework","title":"ADR-001: PydanticAI for Agent Framework","text":"<p>Status: Accepted</p> <p>Context: We needed a framework for building LLM-powered agents with tool calling capabilities.</p> <p>Decision: Use PydanticAI as the agent framework.</p> <p>Rationale: - Type-safe with Pydantic models - Native async support - Clean tool definition API - Multi-provider support - Active development and community</p> <p>Consequences: - Dependency on PydanticAI - Benefits from upstream improvements - May need to adapt to API changes</p>"},{"location":"architecture/decisions/#adr-002-asyncssh-for-ssh-connections","title":"ADR-002: AsyncSSH for SSH Connections","text":"<p>Status: Accepted</p> <p>Context: SSH connectivity is core to Merlya's functionality.</p> <p>Decision: Use asyncssh for all SSH operations.</p> <p>Rationale: - Pure Python, no external dependencies - Async-native for concurrent connections - Full SSH2 protocol support - Jump host support built-in - Active maintenance</p> <p>Consequences: - Async-only API - Connection pooling needed for performance - Memory overhead for many connections</p>"},{"location":"architecture/decisions/#adr-003-connection-pooling","title":"ADR-003: Connection Pooling","text":"<p>Status: Accepted</p> <p>Context: Frequent SSH connections are slow and resource-intensive.</p> <p>Decision: Implement connection pooling with automatic cleanup.</p> <p>Rationale: - Avoid connection overhead for repeated commands - Limit concurrent connections - Automatic cleanup of idle connections - Graceful shutdown handling</p> <p>Implementation: <pre><code>class SSHPool:\n    max_connections: int = 10\n    idle_timeout: int = 300  # 5 minutes\n\n    async def get_connection(host) -&gt; SSHConnection\n    async def release_connection(conn)\n    async def cleanup_idle()\n</code></pre></p>"},{"location":"architecture/decisions/#adr-004-keyring-for-credential-storage","title":"ADR-004: Keyring for Credential Storage","text":"<p>Status: Accepted</p> <p>Context: API keys and credentials need secure storage.</p> <p>Decision: Use the system keyring (via <code>keyring</code> library).</p> <p>Rationale: - OS-level security (Keychain, Secret Service, Credential Manager) - No plaintext secrets in config files - Standard cross-platform solution - Fallback to in-memory with warning</p> <p>Consequences: - Requires keyring backend on Linux - May need user interaction for first-time setup - Headless servers need alternative setup</p>"},{"location":"architecture/decisions/#adr-005-local-intent-classification","title":"ADR-005: Local Intent Classification","text":"<p>Status: Accepted</p> <p>Context: Not all user inputs require LLM processing.</p> <p>Decision: Use ONNX-based local classifier for intent routing.</p> <p>Rationale: - Fast (&lt; 10ms) classification - No API calls for simple intents - Works offline - Reduces API costs</p> <p>Implementation: <pre><code>User Input \u2192 Intent Classifier \u2192 [Simple Intent] \u2192 Direct Handler\n                              \u2192 [Complex Intent] \u2192 LLM Agent\n</code></pre></p> <p>Consequences: - Additional model file (~50MB) - Needs training data for new intents - May misclassify edge cases</p>"},{"location":"architecture/decisions/#adr-006-toml-configuration","title":"ADR-006: TOML Configuration","text":"<p>Status: Accepted</p> <p>Context: Configuration needs to be human-readable and editable.</p> <p>Decision: Use TOML for configuration files.</p> <p>Rationale: - Human-friendly syntax - Good Python support (tomllib in stdlib) - Hierarchical structure - Comments supported - Industry standard for Python projects</p> <p>File Locations: - <code>~/.config/merlya/config.toml</code> - Main config - <code>~/.config/merlya/hosts.toml</code> - SSH hosts</p>"},{"location":"architecture/decisions/#adr-007-plugin-architecture","title":"ADR-007: Plugin Architecture","text":"<p>Status: Proposed</p> <p>Context: Users need to extend Merlya with custom tools.</p> <p>Decision: Entry-point based plugin system.</p> <p>Rationale: - Standard Python packaging approach - Easy distribution via PyPI - Namespace isolation - Lazy loading</p> <p>Proposed Interface: <pre><code># pyproject.toml\n[project.entry-points.\"merlya.tools\"]\nmy_tool = \"my_package:MyTool\"\n\n# Implementation\nclass MyTool(MerlyaTool):\n    name = \"my_tool\"\n    description = \"Does something useful\"\n\n    async def execute(self, params: dict) -&gt; ToolResult:\n        ...\n</code></pre></p>"},{"location":"architecture/decisions/#adr-008-structured-logging","title":"ADR-008: Structured Logging","text":"<p>Status: Accepted</p> <p>Context: Debugging and monitoring require good logging.</p> <p>Decision: Use structlog for structured logging.</p> <p>Rationale: - Structured output (JSON for production) - Human-readable for development - Context binding for request tracing - Performance optimized</p> <p>Log Levels: - DEBUG: Detailed execution flow - INFO: Key operations and results - WARNING: Recoverable issues - ERROR: Failures requiring attention</p>"},{"location":"architecture/decisions/#adr-009-multi-provider-llm-support","title":"ADR-009: Multi-Provider LLM Support","text":"<p>Status: Accepted</p> <p>Context: Users have different LLM provider preferences.</p> <p>Decision: Abstract LLM provider interface with multiple implementations.</p> <p>Supported Providers: - OpenAI (GPT-4o, GPT-4o-mini) - Anthropic (Claude 3.5) - Ollama (local models) - Groq (fast inference)</p> <p>Interface: <pre><code>class LLMProvider(Protocol):\n    async def generate(prompt: str) -&gt; str\n    async def generate_with_tools(prompt: str, tools: list) -&gt; ToolCall\n</code></pre></p>"},{"location":"architecture/decisions/#adr-010-security-model","title":"ADR-010: Security Model","text":"<p>Status: Accepted</p> <p>Context: Merlya executes commands on remote systems.</p> <p>Decision: Implement defense-in-depth security model.</p> <p>Layers: 1. Credential Protection - Keyring storage 2. Command Review - User confirmation for destructive commands 3. Input Validation - Pydantic models for all inputs 4. Audit Logging - All commands logged 5. Principle of Least Privilege - Minimal permissions</p> <p>Dangerous Command Detection: <pre><code>DANGEROUS_PATTERNS = [\n    r\"rm\\s+-rf\",\n    r\"mkfs\",\n    r\"dd\\s+if=\",\n    r\"&gt;\\s*/dev/\",\n    r\"chmod\\s+777\",\n]\n</code></pre></p>"},{"location":"architecture/decisions/#future-considerations","title":"Future Considerations","text":""},{"location":"architecture/decisions/#under-evaluation","title":"Under Evaluation","text":"<ul> <li>WebSocket support for real-time streaming</li> <li>Kubernetes integration via kubectl</li> <li>Terraform integration for IaC</li> <li>Metrics collection for monitoring dashboards</li> </ul>"},{"location":"architecture/decisions/#rejected","title":"Rejected","text":"<ul> <li>GUI Application - Focus on CLI/API for automation</li> <li>Custom LLM training - Too resource-intensive for scope</li> <li>Multi-tenant SaaS - Security complexity, out of scope</li> </ul>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Merlya uses a layered configuration system with sensible defaults.</p>"},{"location":"getting-started/configuration/#configuration-file","title":"Configuration File","text":"<p>Configuration is stored in <code>~/.config/merlya/config.toml</code>:</p> <pre><code>[llm]\nprovider = \"openai\"\nmodel = \"gpt-4o-mini\"\ntemperature = 0.7\nmax_tokens = 4096\n\n[ssh]\ntimeout = 30\nmax_connections = 10\nretry_attempts = 3\n\n[logging]\nlevel = \"INFO\"\nfile = \"~/.config/merlya/merlya.log\"\n</code></pre>"},{"location":"getting-started/configuration/#setting-values","title":"Setting Values","text":"<p>Use the <code>config</code> command to manage settings:</p> <pre><code># Set a value\nmerlya config set llm.provider anthropic\n\n# Get a value\nmerlya config get llm.provider\n\n# List all settings\nmerlya config list\n\n# Reset to defaults\nmerlya config reset\n</code></pre>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"<p>All settings can be overridden with environment variables:</p> <pre><code>export MERLYA_LLM_PROVIDER=openai\nexport MERLYA_LLM_API_KEY=sk-...\nexport MERLYA_LLM_MODEL=gpt-4o\n</code></pre>"},{"location":"getting-started/configuration/#llm-configuration","title":"LLM Configuration","text":""},{"location":"getting-started/configuration/#provider-settings","title":"Provider Settings","text":"Setting Description Default <code>llm.provider</code> LLM provider (openai, anthropic, ollama) <code>openai</code> <code>llm.model</code> Model name <code>gpt-4o-mini</code> <code>llm.api_key</code> API key (stored in keyring) - <code>llm.temperature</code> Response randomness (0-1) <code>0.7</code> <code>llm.max_tokens</code> Max response length <code>4096</code>"},{"location":"getting-started/configuration/#api-keys","title":"API Keys","text":"<p>API keys are stored securely in your system keyring:</p> <ul> <li>macOS: Keychain</li> <li>Linux: Secret Service (GNOME Keyring, KWallet)</li> <li>Windows: Credential Manager</li> </ul> <pre><code># Set API key (stored securely)\nmerlya config set llm.api_key sk-your-key\n\n# Keys are never written to config files\ncat ~/.config/merlya/config.toml | grep api_key\n# (no output)\n</code></pre>"},{"location":"getting-started/configuration/#ssh-configuration","title":"SSH Configuration","text":"Setting Description Default <code>ssh.timeout</code> Connection timeout (seconds) <code>30</code> <code>ssh.max_connections</code> Max concurrent connections <code>10</code> <code>ssh.retry_attempts</code> Retry failed connections <code>3</code> <code>ssh.known_hosts</code> Known hosts file <code>~/.ssh/known_hosts</code>"},{"location":"getting-started/configuration/#hosts-configuration","title":"Hosts Configuration","text":"<p>Define frequently used hosts in <code>~/.config/merlya/hosts.toml</code>:</p> <pre><code>[hosts.web-01]\nhostname = \"web-01.example.com\"\nuser = \"deploy\"\nport = 22\nkey = \"~/.ssh/deploy_key\"\n\n[hosts.db-master]\nhostname = \"db-master.internal\"\nuser = \"admin\"\njump_host = \"bastion.example.com\"\n\n[groups.web-servers]\nhosts = [\"web-01\", \"web-02\", \"web-03\"]\n\n[groups.databases]\nhosts = [\"db-master\", \"db-replica-01\", \"db-replica-02\"]\n</code></pre>"},{"location":"getting-started/configuration/#logging","title":"Logging","text":"Setting Description Default <code>logging.level</code> Log level (DEBUG, INFO, WARNING, ERROR) <code>INFO</code> <code>logging.file</code> Log file path <code>~/.config/merlya/merlya.log</code> <code>logging.format</code> Log format string <code>%(asctime)s - %(levelname)s - %(message)s</code>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>SSH Management Guide</li> <li>LLM Providers Guide</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or higher</li> <li>pip (Python package manager)</li> <li>An LLM provider API key (OpenAI, Anthropic, or local Ollama)</li> </ul>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<p>The recommended way to install Merlya is via pip:</p> <pre><code>pip install merlya\n</code></pre>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<p>For the latest development version:</p> <pre><code>git clone https://github.com/m-kis/merlya.git\ncd merlya\npip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>merlya --version\n</code></pre> <p>You should see output like:</p> <pre><code>merlya 0.5.6\n</code></pre>"},{"location":"getting-started/installation/#shell-completion","title":"Shell Completion","text":"BashZshFish <pre><code># Add to ~/.bashrc\neval \"$(_MERLYA_COMPLETE=bash_source merlya)\"\n</code></pre> <pre><code># Add to ~/.zshrc\neval \"$(_MERLYA_COMPLETE=zsh_source merlya)\"\n</code></pre> <pre><code># Add to ~/.config/fish/completions/merlya.fish\n_MERLYA_COMPLETE=fish_source merlya | source\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Get up and running in 5 minutes</li> <li>Configuration - Configure your LLM provider and settings</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get Merlya up and running in 5 minutes.</p>"},{"location":"getting-started/quickstart/#1-configure-llm-provider","title":"1. Configure LLM Provider","text":"<p>Merlya needs an LLM provider to work. Choose one:</p> OpenAIAnthropicOllama (Local) <pre><code>merlya config set llm.provider openai\nmerlya config set llm.api_key sk-your-api-key\nmerlya config set llm.model gpt-4o-mini\n</code></pre> <pre><code>merlya config set llm.provider anthropic\nmerlya config set llm.api_key sk-ant-your-api-key\nmerlya config set llm.model claude-3-5-sonnet-20241022\n</code></pre> <pre><code># First, install Ollama: https://ollama.ai\nollama pull qwen2.5:7b\n\nmerlya config set llm.provider ollama\nmerlya config set llm.model qwen2.5:7b\n</code></pre>"},{"location":"getting-started/quickstart/#2-start-chatting","title":"2. Start Chatting","text":"<p>Launch the interactive chat:</p> <pre><code>merlya chat\n</code></pre> <p>You'll see a prompt where you can type natural language commands:</p> <pre><code>Merlya &gt; What can you help me with?\n\nI can help you with:\n- Managing SSH connections to servers\n- Executing commands on remote machines\n- Checking system status and metrics\n- Automating routine DevOps tasks\n\nJust describe what you need in plain English!\n</code></pre>"},{"location":"getting-started/quickstart/#3-connect-to-a-server","title":"3. Connect to a Server","text":"<pre><code>Merlya &gt; Connect to my-server.example.com and show me the uptime\n\nI'll connect to my-server.example.com and check the uptime.\n\n&gt; ssh my-server.example.com \"uptime\"\n\n 14:32:01 up 45 days,  3:21,  2 users,  load average: 0.15, 0.10, 0.05\n\nThe server has been running for 45 days with low load averages.\n</code></pre>"},{"location":"getting-started/quickstart/#4-execute-commands","title":"4. Execute Commands","text":"<pre><code>Merlya &gt; Check disk space on all web servers\n\nI'll check disk space on your web servers.\n\n&gt; ssh web-01 \"df -h /\"\n&gt; ssh web-02 \"df -h /\"\n&gt; ssh web-03 \"df -h /\"\n\nSummary:\n- web-01: 45% used (55GB free)\n- web-02: 62% used (38GB free)\n- web-03: 78% used (22GB free) \u26a0\ufe0f\n\nweb-03 is getting low on disk space. Consider cleaning up or expanding.\n</code></pre>"},{"location":"getting-started/quickstart/#common-commands","title":"Common Commands","text":"Command Description <code>merlya chat</code> Start interactive chat <code>merlya config list</code> Show current configuration <code>merlya config set KEY VALUE</code> Set a configuration value <code>merlya hosts list</code> List configured hosts <code>merlya hosts add NAME HOST</code> Add a new host"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Guide - Advanced configuration options</li> <li>SSH Management - Deep dive into SSH features</li> <li>LLM Providers - Configure different LLM providers</li> </ul>"},{"location":"guides/automation/","title":"Automation","text":"<p>Automate infrastructure tasks with Merlya's scripting and scheduling capabilities.</p>"},{"location":"guides/automation/#non-interactive-mode","title":"Non-Interactive Mode","text":"<p>Run Merlya commands without interactive prompts:</p> <pre><code># Single command\nmerlya run \"Check disk space on all web servers\"\n\n# From file\nmerlya run --file tasks.txt\n\n# With confirmation disabled (use with caution)\nmerlya run --yes \"Restart nginx on web-01\"\n</code></pre>"},{"location":"guides/automation/#task-files","title":"Task Files","text":"<p>Create reusable task files:</p> <pre><code># tasks/daily-checks.yml\nname: Daily Infrastructure Checks\ntasks:\n  - description: Check disk space\n    prompt: Check disk usage on all servers, warn if above 80%\n\n  - description: Check memory\n    prompt: Check memory usage on all servers\n\n  - description: Check services\n    prompt: Verify nginx and postgres are running on all servers\n</code></pre> <p>Run the task file:</p> <pre><code>merlya run --file tasks/daily-checks.yml\n</code></pre>"},{"location":"guides/automation/#cron-integration","title":"Cron Integration","text":"<p>Schedule Merlya tasks with cron:</p> <pre><code># Edit crontab\ncrontab -e\n\n# Daily health check at 6 AM\n0 6 * * * /usr/local/bin/merlya run \"Run daily health checks\" &gt;&gt; /var/log/merlya-daily.log 2&gt;&amp;1\n\n# Hourly disk check\n0 * * * * /usr/local/bin/merlya run \"Check disk space, alert if above 90%\" &gt;&gt; /var/log/merlya-disk.log 2&gt;&amp;1\n</code></pre>"},{"location":"guides/automation/#webhooks","title":"Webhooks","text":"<p>Trigger Merlya from webhooks:</p> <pre><code>#!/bin/bash\n# webhook-handler.sh\n\nPAYLOAD=$(cat)\nEVENT=$(echo $PAYLOAD | jq -r '.event')\n\ncase $EVENT in\n  \"deploy\")\n    merlya run \"Deploy latest version to staging servers\"\n    ;;\n  \"rollback\")\n    merlya run \"Rollback to previous version on staging\"\n    ;;\n  \"scale-up\")\n    merlya run \"Start 2 additional web servers\"\n    ;;\nesac\n</code></pre>"},{"location":"guides/automation/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"guides/automation/#github-actions","title":"GitHub Actions","text":"<pre><code>name: Deploy with Merlya\n\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install Merlya\n        run: pip install merlya\n\n      - name: Configure Merlya\n        run: |\n          merlya config set llm.provider openai\n          merlya config set llm.api_key ${{ secrets.OPENAI_API_KEY }}\n\n      - name: Deploy\n        run: |\n          merlya run --yes \"Deploy the latest code to production servers\"\n</code></pre>"},{"location":"guides/automation/#gitlab-ci","title":"GitLab CI","text":"<pre><code>deploy:\n  stage: deploy\n  script:\n    - pip install merlya\n    - merlya config set llm.provider openai\n    - merlya config set llm.api_key $OPENAI_API_KEY\n    - merlya run --yes \"Deploy version $CI_COMMIT_TAG to production\"\n  only:\n    - tags\n</code></pre>"},{"location":"guides/automation/#output-formats","title":"Output Formats","text":"<p>Control output format for automation:</p> <pre><code># JSON output (for parsing)\nmerlya run --format json \"List all servers with high CPU\"\n\n# Quiet mode (only results)\nmerlya run --quiet \"Check nginx status\"\n\n# Verbose mode (full logging)\nmerlya run --verbose \"Deploy to production\"\n</code></pre>"},{"location":"guides/automation/#json-output-example","title":"JSON Output Example","text":"<pre><code>merlya run --format json \"Check disk space on web-01\"\n</code></pre> <pre><code>{\n  \"success\": true,\n  \"server\": \"web-01\",\n  \"command\": \"df -h /\",\n  \"output\": \"Filesystem      Size  Used Avail Use%\\n/dev/sda1       100G   45G   55G  45%\",\n  \"analysis\": {\n    \"disk_used_percent\": 45,\n    \"disk_free_gb\": 55,\n    \"status\": \"healthy\"\n  }\n}\n</code></pre>"},{"location":"guides/automation/#error-handling","title":"Error Handling","text":"<p>Handle errors in scripts:</p> <pre><code>#!/bin/bash\nset -e\n\n# Run with error handling\nif merlya run --quiet \"Check if all services are healthy\"; then\n    echo \"All services healthy\"\nelse\n    echo \"Service check failed!\"\n    merlya run \"Send alert to ops team about service failures\"\n    exit 1\nfi\n</code></pre>"},{"location":"guides/automation/#logging","title":"Logging","text":"<p>Configure logging for automation:</p> <pre><code># Set log level\nmerlya config set logging.level DEBUG\n\n# Set log file\nmerlya config set logging.file /var/log/merlya/automation.log\n\n# Run with specific log file\nMERLYA_LOG_FILE=/tmp/task.log merlya run \"Check servers\"\n</code></pre>"},{"location":"guides/automation/#best-practices","title":"Best Practices","text":"<ol> <li>Use <code>--yes</code> carefully - Only for well-tested tasks</li> <li>Log everything - Keep records of automated actions</li> <li>Set timeouts - Prevent hanging tasks</li> <li>Use JSON output - For reliable parsing</li> <li>Test in staging - Before automating production tasks</li> <li>Monitor failures - Set up alerts for failed tasks</li> </ol>"},{"location":"guides/automation/#examples","title":"Examples","text":""},{"location":"guides/automation/#daily-backup-check","title":"Daily Backup Check","text":"<pre><code>#!/bin/bash\n# check-backups.sh\n\nLOG_FILE=\"/var/log/merlya/backup-check.log\"\n\necho \"$(date): Starting backup check\" &gt;&gt; $LOG_FILE\n\nRESULT=$(merlya run --format json \"Verify all database backups from last 24h exist and are valid\")\n\nif echo $RESULT | jq -e '.success' &gt; /dev/null; then\n    echo \"$(date): Backup check passed\" &gt;&gt; $LOG_FILE\nelse\n    echo \"$(date): Backup check FAILED\" &gt;&gt; $LOG_FILE\n    merlya run \"Send urgent alert: backup verification failed\"\nfi\n</code></pre>"},{"location":"guides/automation/#auto-scaling","title":"Auto-Scaling","text":"<pre><code>#!/bin/bash\n# auto-scale.sh\n\nCPU=$(merlya run --format json \"Get average CPU across web tier\" | jq '.cpu_percent')\n\nif (( $(echo \"$CPU &gt; 80\" | bc -l) )); then\n    merlya run --yes \"Scale up web tier by 2 instances\"\nelif (( $(echo \"$CPU &lt; 20\" | bc -l) )); then\n    merlya run --yes \"Scale down web tier by 1 instance (keep minimum 2)\"\nfi\n</code></pre>"},{"location":"guides/llm-providers/","title":"LLM Providers","text":"<p>Merlya supports multiple LLM providers, from cloud APIs to local models.</p>"},{"location":"guides/llm-providers/#supported-providers","title":"Supported Providers","text":"Provider Models Pros Cons OpenAI GPT-4o, GPT-4o-mini Best quality, fast Paid API Anthropic Claude 3.5 Sonnet Great reasoning Paid API Ollama Qwen, Llama, Mistral Free, private Requires GPU/CPU Groq Llama 3.3, Mixtral Ultra fast, free tier Rate limited"},{"location":"guides/llm-providers/#openai","title":"OpenAI","text":""},{"location":"guides/llm-providers/#setup","title":"Setup","text":"<pre><code>merlya config set llm.provider openai\nmerlya config set llm.api_key sk-your-api-key\nmerlya config set llm.model gpt-4o-mini\n</code></pre>"},{"location":"guides/llm-providers/#recommended-models","title":"Recommended Models","text":"Model Speed Quality Cost <code>gpt-4o</code> Fast Excellent $$ <code>gpt-4o-mini</code> Very fast Great $ <code>gpt-4-turbo</code> Medium Excellent $$$"},{"location":"guides/llm-providers/#custom-base-url","title":"Custom Base URL","text":"<p>For Azure OpenAI or proxies:</p> <pre><code>merlya config set llm.base_url https://your-endpoint.openai.azure.com\n</code></pre>"},{"location":"guides/llm-providers/#anthropic","title":"Anthropic","text":""},{"location":"guides/llm-providers/#setup_1","title":"Setup","text":"<pre><code>merlya config set llm.provider anthropic\nmerlya config set llm.api_key sk-ant-your-api-key\nmerlya config set llm.model claude-3-5-sonnet-20241022\n</code></pre>"},{"location":"guides/llm-providers/#recommended-models_1","title":"Recommended Models","text":"Model Speed Quality Cost <code>claude-3-5-sonnet-20241022</code> Fast Excellent $$ <code>claude-3-5-haiku-20241022</code> Very fast Great $ <code>claude-3-opus-20240229</code> Slow Best $$$"},{"location":"guides/llm-providers/#ollama-local","title":"Ollama (Local)","text":"<p>Run models locally with Ollama.</p>"},{"location":"guides/llm-providers/#setup_2","title":"Setup","text":"<pre><code># Install Ollama\ncurl -fsSL https://ollama.ai/install.sh | sh\n\n# Pull a model\nollama pull qwen2.5:7b\n\n# Configure Merlya\nmerlya config set llm.provider ollama\nmerlya config set llm.model qwen2.5:7b\nmerlya config set llm.base_url http://localhost:11434\n</code></pre>"},{"location":"guides/llm-providers/#recommended-models_2","title":"Recommended Models","text":"Model RAM Quality Speed <code>qwen2.5:7b</code> 8GB Great Fast <code>llama3.2:3b</code> 4GB Good Very fast <code>mistral-nemo:12b</code> 16GB Excellent Medium <code>codellama:13b</code> 16GB Great for code Medium"},{"location":"guides/llm-providers/#gpu-acceleration","title":"GPU Acceleration","text":"<p>Ollama automatically uses GPU if available:</p> <pre><code># Check GPU usage\nollama ps\n\n# Force CPU only\nOLLAMA_GPU_LAYERS=0 ollama serve\n</code></pre>"},{"location":"guides/llm-providers/#groq","title":"Groq","text":"<p>Ultra-fast inference with free tier.</p>"},{"location":"guides/llm-providers/#setup_3","title":"Setup","text":"<pre><code>merlya config set llm.provider groq\nmerlya config set llm.api_key gsk_your-api-key\nmerlya config set llm.model llama-3.3-70b-versatile\n</code></pre>"},{"location":"guides/llm-providers/#available-models","title":"Available Models","text":"Model Tokens/sec Quality <code>llama-3.3-70b-versatile</code> ~300 Excellent <code>llama-3.1-8b-instant</code> ~750 Good <code>mixtral-8x7b-32768</code> ~500 Great"},{"location":"guides/llm-providers/#rate-limits-free-tier","title":"Rate Limits (Free Tier)","text":"<ul> <li>30 requests/minute</li> <li>14,400 requests/day</li> </ul>"},{"location":"guides/llm-providers/#switching-providers","title":"Switching Providers","text":"<p>Easily switch between providers:</p> <pre><code># Use OpenAI for complex tasks\nmerlya config set llm.provider openai\nmerlya chat\n\n# Switch to Ollama for privacy\nmerlya config set llm.provider ollama\nmerlya chat\n</code></pre>"},{"location":"guides/llm-providers/#environment-variables","title":"Environment Variables","text":"<p>Override settings with environment variables:</p> <pre><code>export MERLYA_LLM_PROVIDER=anthropic\nexport MERLYA_LLM_API_KEY=sk-ant-xxx\nexport MERLYA_LLM_MODEL=claude-3-5-sonnet-20241022\n\nmerlya chat  # Uses Anthropic\n</code></pre>"},{"location":"guides/llm-providers/#custom-providers","title":"Custom Providers","text":"<p>Add custom OpenAI-compatible providers:</p> <pre><code>merlya config set llm.provider openai\nmerlya config set llm.base_url https://api.your-provider.com/v1\nmerlya config set llm.api_key your-api-key\nmerlya config set llm.model your-model-name\n</code></pre> <p>Compatible providers:</p> <ul> <li>Together AI</li> <li>Anyscale</li> <li>Fireworks AI</li> <li>Perplexity</li> <li>Local vLLM/llama.cpp servers</li> </ul>"},{"location":"guides/llm-providers/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/llm-providers/#api-key-issues","title":"API Key Issues","text":"<pre><code># Verify API key is set\nmerlya config get llm.api_key\n\n# Re-set API key\nmerlya config set llm.api_key sk-new-key\n</code></pre>"},{"location":"guides/llm-providers/#rate-limiting","title":"Rate Limiting","text":"<pre><code>Error: Rate limit exceeded\n\n# Solutions:\n# 1. Wait and retry\n# 2. Switch to a different provider\n# 3. Upgrade your API plan\n</code></pre>"},{"location":"guides/llm-providers/#ollama-not-responding","title":"Ollama Not Responding","text":"<pre><code># Check if Ollama is running\ncurl http://localhost:11434/api/tags\n\n# Restart Ollama\nsystemctl restart ollama\n# or\nollama serve\n</code></pre>"},{"location":"guides/ssh-management/","title":"SSH Management","text":"<p>Merlya provides powerful SSH management capabilities with connection pooling, jump hosts, and intelligent retry logic.</p>"},{"location":"guides/ssh-management/#connecting-to-servers","title":"Connecting to Servers","text":""},{"location":"guides/ssh-management/#basic-connection","title":"Basic Connection","text":"<pre><code>Merlya &gt; Connect to server.example.com\n\nConnecting to server.example.com...\nConnected successfully.\n\nMerlya &gt; Run \"uptime\"\n\n&gt; ssh server.example.com \"uptime\"\n 10:30:15 up 30 days,  2:45,  1 user,  load average: 0.08, 0.12, 0.09\n</code></pre>"},{"location":"guides/ssh-management/#with-credentials","title":"With Credentials","text":"<pre><code>Merlya &gt; Connect to server.example.com as user admin with key ~/.ssh/admin_key\n\nConnecting to server.example.com as admin...\nUsing key: ~/.ssh/admin_key\nConnected successfully.\n</code></pre>"},{"location":"guides/ssh-management/#connection-pooling","title":"Connection Pooling","text":"<p>Merlya automatically manages SSH connections:</p> <ul> <li>Reuses connections - No reconnection overhead</li> <li>Automatic cleanup - Idle connections are closed</li> <li>Concurrent connections - Execute on multiple servers in parallel</li> </ul> <pre><code>Merlya &gt; Check uptime on all web servers\n\nExecuting on 5 servers in parallel...\n\nweb-01: up 45 days\nweb-02: up 45 days\nweb-03: up 12 days\nweb-04: up 45 days\nweb-05: up 3 days (recently restarted)\n</code></pre>"},{"location":"guides/ssh-management/#jump-hosts-bastion","title":"Jump Hosts (Bastion)","text":"<p>Connect through a bastion/jump host:</p> <pre><code>Merlya &gt; Connect to internal-db via bastion.example.com\n\nConnecting through jump host: bastion.example.com\nConnected to internal-db via bastion.\n</code></pre> <p>Configure in <code>hosts.toml</code>:</p> <pre><code>[hosts.internal-db]\nhostname = \"10.0.1.50\"\nuser = \"dbadmin\"\njump_host = \"bastion.example.com\"\n</code></pre>"},{"location":"guides/ssh-management/#host-groups","title":"Host Groups","text":"<p>Define and use host groups:</p> <pre><code># ~/.config/merlya/hosts.toml\n[groups.web-tier]\nhosts = [\"web-01\", \"web-02\", \"web-03\"]\n\n[groups.db-tier]\nhosts = [\"db-master\", \"db-replica-01\"]\n</code></pre> <pre><code>Merlya &gt; Restart nginx on all web-tier servers\n\nI'll restart nginx on all web-tier servers (web-01, web-02, web-03).\n\n&gt; ssh web-01 \"sudo systemctl restart nginx\"\n&gt; ssh web-02 \"sudo systemctl restart nginx\"\n&gt; ssh web-03 \"sudo systemctl restart nginx\"\n\nNginx restarted on all 3 servers.\n</code></pre>"},{"location":"guides/ssh-management/#file-transfer","title":"File Transfer","text":""},{"location":"guides/ssh-management/#upload-files","title":"Upload Files","text":"<pre><code>Merlya &gt; Upload config.yml to /etc/app/ on web-01\n\nUploading config.yml to web-01:/etc/app/config.yml...\nTransfer complete (2.3 KB).\n</code></pre>"},{"location":"guides/ssh-management/#download-files","title":"Download Files","text":"<pre><code>Merlya &gt; Download /var/log/app.log from web-01\n\nDownloading web-01:/var/log/app.log...\nSaved to: ./app.log (45 KB)\n</code></pre>"},{"location":"guides/ssh-management/#error-handling","title":"Error Handling","text":""},{"location":"guides/ssh-management/#automatic-retry","title":"Automatic Retry","text":"<p>Failed connections are automatically retried:</p> <pre><code>Merlya &gt; Connect to flaky-server.example.com\n\nConnection attempt 1 failed: Connection timeout\nRetrying in 5 seconds...\nConnection attempt 2 succeeded.\nConnected to flaky-server.example.com.\n</code></pre>"},{"location":"guides/ssh-management/#connection-errors","title":"Connection Errors","text":"<pre><code>Merlya &gt; Connect to unknown-server.example.com\n\nUnable to connect to unknown-server.example.com:\n- Error: Host not found\n- Suggestion: Check the hostname or add it to /etc/hosts\n</code></pre>"},{"location":"guides/ssh-management/#security","title":"Security","text":""},{"location":"guides/ssh-management/#host-key-verification","title":"Host Key Verification","text":"<pre><code>Merlya &gt; Connect to new-server.example.com\n\nWarning: Unknown host key for new-server.example.com\nFingerprint: SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\nDo you want to add this host to known_hosts? [y/N]\n</code></pre>"},{"location":"guides/ssh-management/#key-based-authentication","title":"Key-Based Authentication","text":"<p>Merlya supports various SSH key types:</p> <ul> <li>RSA (2048+ bits)</li> <li>Ed25519 (recommended)</li> <li>ECDSA</li> </ul> <pre><code># Generate a new key\nssh-keygen -t ed25519 -f ~/.ssh/merlya_key\n\n# Configure Merlya to use it\nmerlya config set ssh.default_key ~/.ssh/merlya_key\n</code></pre>"},{"location":"guides/ssh-management/#best-practices","title":"Best Practices","text":"<ol> <li>Use SSH keys instead of passwords</li> <li>Configure jump hosts for internal servers</li> <li>Use host groups for batch operations</li> <li>Set appropriate timeouts for slow networks</li> <li>Review commands before execution on production</li> </ol>"},{"location":"guides/ssh-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/ssh-management/#connection-timeout","title":"Connection Timeout","text":"<pre><code># Increase timeout\nmerlya config set ssh.timeout 60\n</code></pre>"},{"location":"guides/ssh-management/#permission-denied","title":"Permission Denied","text":"<pre><code># Check key permissions\nchmod 600 ~/.ssh/your_key\nchmod 700 ~/.ssh\n</code></pre>"},{"location":"guides/ssh-management/#too-many-connections","title":"Too Many Connections","text":"<pre><code># Adjust pool size\nmerlya config set ssh.max_connections 20\n</code></pre>"},{"location":"reference/api/","title":"API Reference","text":"<p>Merlya can be used as a Python library in your own applications.</p>"},{"location":"reference/api/#installation","title":"Installation","text":"<pre><code>pip install merlya\n</code></pre>"},{"location":"reference/api/#quick-start","title":"Quick Start","text":"<pre><code>from merlya import Merlya\n\n# Initialize with default config\nagent = Merlya()\n\n# Or with custom settings\nagent = Merlya(\n    provider=\"openai\",\n    model=\"gpt-4o-mini\",\n    api_key=\"sk-...\"\n)\n\n# Run a task\nresult = await agent.run(\"Check disk space on web servers\")\nprint(result)\n</code></pre>"},{"location":"reference/api/#core-classes","title":"Core Classes","text":""},{"location":"reference/api/#merlya","title":"Merlya","text":"<p>Main entry point for the library.</p> <pre><code>class Merlya:\n    def __init__(\n        self,\n        provider: str = \"openai\",\n        model: str = None,\n        api_key: str = None,\n        config_path: str = None\n    )\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>provider</code> str LLM provider name <code>model</code> str Model identifier <code>api_key</code> str API key (uses keyring if not provided) <code>config_path</code> str Custom config file path <p>Methods:</p>"},{"location":"reference/api/#run","title":"run","text":"<p>Execute a natural language task.</p> <pre><code>async def run(\n    self,\n    prompt: str,\n    confirm: bool = True,\n    timeout: int = 300\n) -&gt; TaskResult\n</code></pre>"},{"location":"reference/api/#chat","title":"chat","text":"<p>Start an interactive chat session.</p> <pre><code>async def chat(\n    self,\n    system_prompt: str = None,\n    history: list = None\n) -&gt; None\n</code></pre>"},{"location":"reference/api/#connect","title":"connect","text":"<p>Connect to an SSH host.</p> <pre><code>async def connect(\n    self,\n    host: str,\n    user: str = None,\n    key: str = None\n) -&gt; SSHConnection\n</code></pre>"},{"location":"reference/api/#sshconnection","title":"SSHConnection","text":"<p>Represents an SSH connection.</p> <pre><code>class SSHConnection:\n    hostname: str\n    user: str\n    connected: bool\n</code></pre> <p>Methods:</p>"},{"location":"reference/api/#execute","title":"execute","text":"<p>Run a command on the remote host.</p> <pre><code>async def execute(\n    self,\n    command: str,\n    sudo: bool = False,\n    timeout: int = 60\n) -&gt; CommandResult\n</code></pre>"},{"location":"reference/api/#upload","title":"upload","text":"<p>Upload a file to the remote host.</p> <pre><code>async def upload(\n    self,\n    local_path: str,\n    remote_path: str\n) -&gt; None\n</code></pre>"},{"location":"reference/api/#download","title":"download","text":"<p>Download a file from the remote host.</p> <pre><code>async def download(\n    self,\n    remote_path: str,\n    local_path: str\n) -&gt; None\n</code></pre>"},{"location":"reference/api/#close","title":"close","text":"<p>Close the connection.</p> <pre><code>async def close() -&gt; None\n</code></pre>"},{"location":"reference/api/#taskresult","title":"TaskResult","text":"<p>Result of a task execution.</p> <pre><code>@dataclass\nclass TaskResult:\n    success: bool\n    output: str\n    commands: list[CommandResult]\n    analysis: str\n    duration: float\n</code></pre>"},{"location":"reference/api/#commandresult","title":"CommandResult","text":"<p>Result of a single command execution.</p> <pre><code>@dataclass\nclass CommandResult:\n    command: str\n    stdout: str\n    stderr: str\n    exit_code: int\n    host: str\n    duration: float\n</code></pre>"},{"location":"reference/api/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/api/#basic-task-execution","title":"Basic Task Execution","text":"<pre><code>import asyncio\nfrom merlya import Merlya\n\nasync def main():\n    agent = Merlya()\n\n    # Run a task\n    result = await agent.run(\n        \"Check if nginx is running on web-01\",\n        confirm=False\n    )\n\n    if result.success:\n        print(f\"Output: {result.output}\")\n    else:\n        print(f\"Failed: {result.output}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/api/#ssh-operations","title":"SSH Operations","text":"<pre><code>import asyncio\nfrom merlya import Merlya\n\nasync def main():\n    agent = Merlya()\n\n    # Connect to a server\n    conn = await agent.connect(\"web-01.example.com\", user=\"deploy\")\n\n    # Execute commands\n    result = await conn.execute(\"uptime\")\n    print(f\"Uptime: {result.stdout}\")\n\n    result = await conn.execute(\"df -h /\")\n    print(f\"Disk: {result.stdout}\")\n\n    # Close connection\n    await conn.close()\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/api/#batch-operations","title":"Batch Operations","text":"<pre><code>import asyncio\nfrom merlya import Merlya\n\nasync def check_server(agent, hostname):\n    conn = await agent.connect(hostname)\n    result = await conn.execute(\"uptime\")\n    await conn.close()\n    return hostname, result.stdout\n\nasync def main():\n    agent = Merlya()\n    servers = [\"web-01\", \"web-02\", \"web-03\"]\n\n    # Run in parallel\n    tasks = [check_server(agent, s) for s in servers]\n    results = await asyncio.gather(*tasks)\n\n    for hostname, uptime in results:\n        print(f\"{hostname}: {uptime}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/api/#custom-llm-provider","title":"Custom LLM Provider","text":"<pre><code>from merlya import Merlya\n\n# Use Ollama\nagent = Merlya(\n    provider=\"ollama\",\n    model=\"qwen2.5:7b\",\n    base_url=\"http://localhost:11434\"\n)\n\n# Use Anthropic\nagent = Merlya(\n    provider=\"anthropic\",\n    model=\"claude-3-5-sonnet-20241022\",\n    api_key=\"sk-ant-...\"\n)\n</code></pre>"},{"location":"reference/api/#error-handling","title":"Error Handling","text":"<pre><code>import asyncio\nfrom merlya import Merlya\nfrom merlya.exceptions import (\n    ConnectionError,\n    AuthenticationError,\n    CommandError\n)\n\nasync def main():\n    agent = Merlya()\n\n    try:\n        conn = await agent.connect(\"server.example.com\")\n        result = await conn.execute(\"some-command\")\n    except ConnectionError as e:\n        print(f\"Connection failed: {e}\")\n    except AuthenticationError as e:\n        print(f\"Authentication failed: {e}\")\n    except CommandError as e:\n        print(f\"Command failed: {e.exit_code} - {e.stderr}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/api/#type-hints","title":"Type Hints","text":"<p>Merlya is fully typed. Use with your favorite IDE for autocompletion:</p> <pre><code>from merlya import Merlya, TaskResult, SSHConnection\n\nasync def my_function(agent: Merlya) -&gt; TaskResult:\n    return await agent.run(\"Check servers\")\n</code></pre>"},{"location":"reference/cli/","title":"CLI Reference","text":"<p>Complete reference for all Merlya CLI commands.</p>"},{"location":"reference/cli/#global-options","title":"Global Options","text":"<pre><code>merlya [OPTIONS] COMMAND [ARGS]\n\nOptions:\n  --version       Show version and exit\n  --help          Show help message and exit\n  -v, --verbose   Enable verbose output\n  -q, --quiet     Suppress non-essential output\n  --config FILE   Use specific config file\n</code></pre>"},{"location":"reference/cli/#commands","title":"Commands","text":""},{"location":"reference/cli/#chat","title":"chat","text":"<p>Start an interactive chat session.</p> <pre><code>merlya chat [OPTIONS]\n\nOptions:\n  --model MODEL       Override configured model\n  --provider PROVIDER Override configured provider\n  --system PROMPT     Custom system prompt\n  --history FILE      Load chat history from file\n</code></pre> <p>Examples:</p> <pre><code># Basic chat\nmerlya chat\n\n# Use specific model\nmerlya chat --model gpt-4o\n\n# With custom system prompt\nmerlya chat --system \"You are a Kubernetes expert\"\n</code></pre>"},{"location":"reference/cli/#run","title":"run","text":"<p>Execute a single command or task.</p> <pre><code>merlya run [OPTIONS] PROMPT\n\nOptions:\n  -y, --yes           Skip confirmation prompts\n  -f, --file FILE     Load prompts from file\n  --format FORMAT     Output format (text, json, yaml)\n  --timeout SECONDS   Command timeout\n</code></pre> <p>Examples:</p> <pre><code># Single command\nmerlya run \"Check disk space on web servers\"\n\n# With auto-confirm\nmerlya run --yes \"Restart nginx on web-01\"\n\n# JSON output\nmerlya run --format json \"List all servers\"\n</code></pre>"},{"location":"reference/cli/#config","title":"config","text":"<p>Manage configuration settings.</p> <pre><code>merlya config COMMAND [ARGS]\n\nCommands:\n  get KEY           Get a configuration value\n  set KEY VALUE     Set a configuration value\n  list              List all configuration\n  reset             Reset to defaults\n  path              Show config file path\n</code></pre> <p>Examples:</p> <pre><code># Set LLM provider\nmerlya config set llm.provider openai\n\n# Get current model\nmerlya config get llm.model\n\n# List all settings\nmerlya config list\n\n# Show config file location\nmerlya config path\n</code></pre>"},{"location":"reference/cli/#hosts","title":"hosts","text":"<p>Manage SSH hosts.</p> <pre><code>merlya hosts COMMAND [ARGS]\n\nCommands:\n  list              List all configured hosts\n  add NAME HOST     Add a new host\n  remove NAME       Remove a host\n  show NAME         Show host details\n  test NAME         Test connection to host\n  groups            List host groups\n</code></pre> <p>Examples:</p> <pre><code># List hosts\nmerlya hosts list\n\n# Add a host\nmerlya hosts add web-01 web-01.example.com --user deploy\n\n# Test connection\nmerlya hosts test web-01\n\n# Show host details\nmerlya hosts show web-01\n</code></pre>"},{"location":"reference/cli/#connect","title":"connect","text":"<p>Connect to a specific host.</p> <pre><code>merlya connect [OPTIONS] HOST\n\nOptions:\n  -u, --user USER     SSH username\n  -p, --port PORT     SSH port (default: 22)\n  -k, --key FILE      SSH private key\n  -j, --jump HOST     Jump host for connection\n</code></pre> <p>Examples:</p> <pre><code># Basic connection\nmerlya connect web-01\n\n# With specific user\nmerlya connect web-01 --user admin\n\n# Through jump host\nmerlya connect internal-db --jump bastion\n</code></pre>"},{"location":"reference/cli/#exec","title":"exec","text":"<p>Execute a command on remote hosts.</p> <pre><code>merlya exec [OPTIONS] HOST COMMAND\n\nOptions:\n  --sudo              Run with sudo\n  --timeout SECONDS   Command timeout\n  --parallel          Run on multiple hosts in parallel\n</code></pre> <p>Examples:</p> <pre><code># Run command\nmerlya exec web-01 \"uptime\"\n\n# With sudo\nmerlya exec web-01 --sudo \"systemctl restart nginx\"\n\n# On multiple hosts\nmerlya exec \"web-*\" --parallel \"df -h\"\n</code></pre>"},{"location":"reference/cli/#upload-download","title":"upload / download","text":"<p>Transfer files to/from remote hosts.</p> <pre><code>merlya upload [OPTIONS] LOCAL_FILE HOST:REMOTE_PATH\nmerlya download [OPTIONS] HOST:REMOTE_PATH LOCAL_FILE\n\nOptions:\n  --recursive         Transfer directories\n  --preserve          Preserve permissions\n</code></pre> <p>Examples:</p> <pre><code># Upload file\nmerlya upload config.yml web-01:/etc/app/\n\n# Download file\nmerlya download web-01:/var/log/app.log ./\n\n# Upload directory\nmerlya upload --recursive ./configs/ web-01:/etc/app/\n</code></pre>"},{"location":"reference/cli/#logs","title":"logs","text":"<p>View and manage logs.</p> <pre><code>merlya logs [OPTIONS]\n\nOptions:\n  --lines N           Show last N lines (default: 50)\n  --follow            Follow log output\n  --level LEVEL       Filter by log level\n  --clear             Clear log file\n</code></pre> <p>Examples:</p> <pre><code># View recent logs\nmerlya logs\n\n# Follow logs\nmerlya logs --follow\n\n# Filter errors\nmerlya logs --level ERROR\n</code></pre>"},{"location":"reference/cli/#exit-codes","title":"Exit Codes","text":"Code Meaning 0 Success 1 General error 2 Configuration error 3 Connection error 4 Authentication error 5 Command execution error 130 Interrupted (Ctrl+C)"},{"location":"reference/cli/#environment-variables","title":"Environment Variables","text":"Variable Description <code>MERLYA_CONFIG</code> Config file path <code>MERLYA_LLM_PROVIDER</code> LLM provider <code>MERLYA_LLM_API_KEY</code> LLM API key <code>MERLYA_LLM_MODEL</code> LLM model name <code>MERLYA_LOG_LEVEL</code> Logging level <code>MERLYA_SSH_TIMEOUT</code> SSH timeout"},{"location":"reference/configuration/","title":"Configuration Reference","text":"<p>Complete reference for all configuration options.</p>"},{"location":"reference/configuration/#configuration-files","title":"Configuration Files","text":"File Purpose <code>~/.config/merlya/config.toml</code> Main configuration <code>~/.config/merlya/hosts.toml</code> SSH hosts definitions <code>~/.config/merlya/history.json</code> Chat history"},{"location":"reference/configuration/#llm-settings","title":"LLM Settings","text":""},{"location":"reference/configuration/#llmprovider","title":"llm.provider","text":"<p>LLM provider to use.</p> Type Default Values string <code>openai</code> <code>openai</code>, <code>anthropic</code>, <code>ollama</code>, <code>groq</code> <pre><code>[llm]\nprovider = \"openai\"\n</code></pre>"},{"location":"reference/configuration/#llmmodel","title":"llm.model","text":"<p>Model name/identifier.</p> Type Default string <code>gpt-4o-mini</code> <pre><code>[llm]\nmodel = \"gpt-4o-mini\"\n</code></pre> <p>Provider-specific defaults:</p> Provider Default Model OpenAI <code>gpt-4o-mini</code> Anthropic <code>claude-3-5-sonnet-20241022</code> Ollama <code>qwen2.5:7b</code> Groq <code>llama-3.3-70b-versatile</code>"},{"location":"reference/configuration/#llmapi_key","title":"llm.api_key","text":"<p>API key for the provider. Stored securely in system keyring.</p> Type Default string (none) <pre><code># Set via CLI (recommended)\nmerlya config set llm.api_key sk-your-key\n</code></pre> <p>Security</p> <p>API keys are stored in your system's secure keyring, not in config files.</p>"},{"location":"reference/configuration/#llmbase_url","title":"llm.base_url","text":"<p>Custom API endpoint URL.</p> Type Default string Provider default <pre><code>[llm]\nbase_url = \"https://api.your-provider.com/v1\"\n</code></pre>"},{"location":"reference/configuration/#llmtemperature","title":"llm.temperature","text":"<p>Response randomness (0 = deterministic, 1 = creative).</p> Type Default Range float <code>0.7</code> 0.0 - 1.0 <pre><code>[llm]\ntemperature = 0.7\n</code></pre>"},{"location":"reference/configuration/#llmmax_tokens","title":"llm.max_tokens","text":"<p>Maximum response length in tokens.</p> Type Default Range integer <code>4096</code> 1 - model max <pre><code>[llm]\nmax_tokens = 4096\n</code></pre>"},{"location":"reference/configuration/#ssh-settings","title":"SSH Settings","text":""},{"location":"reference/configuration/#sshtimeout","title":"ssh.timeout","text":"<p>Connection timeout in seconds.</p> Type Default integer <code>30</code> <pre><code>[ssh]\ntimeout = 30\n</code></pre>"},{"location":"reference/configuration/#sshmax_connections","title":"ssh.max_connections","text":"<p>Maximum concurrent SSH connections.</p> Type Default Range integer <code>10</code> 1 - 100 <pre><code>[ssh]\nmax_connections = 10\n</code></pre>"},{"location":"reference/configuration/#sshretry_attempts","title":"ssh.retry_attempts","text":"<p>Number of retry attempts for failed connections.</p> Type Default integer <code>3</code> <pre><code>[ssh]\nretry_attempts = 3\n</code></pre>"},{"location":"reference/configuration/#sshretry_delay","title":"ssh.retry_delay","text":"<p>Delay between retry attempts in seconds.</p> Type Default integer <code>5</code> <pre><code>[ssh]\nretry_delay = 5\n</code></pre>"},{"location":"reference/configuration/#sshknown_hosts","title":"ssh.known_hosts","text":"<p>Path to known_hosts file.</p> Type Default string <code>~/.ssh/known_hosts</code> <pre><code>[ssh]\nknown_hosts = \"~/.ssh/known_hosts\"\n</code></pre>"},{"location":"reference/configuration/#sshdefault_key","title":"ssh.default_key","text":"<p>Default SSH private key.</p> Type Default string <code>~/.ssh/id_ed25519</code> <pre><code>[ssh]\ndefault_key = \"~/.ssh/id_ed25519\"\n</code></pre>"},{"location":"reference/configuration/#logging-settings","title":"Logging Settings","text":""},{"location":"reference/configuration/#logginglevel","title":"logging.level","text":"<p>Logging verbosity level.</p> Type Default Values string <code>INFO</code> <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code> <pre><code>[logging]\nlevel = \"INFO\"\n</code></pre>"},{"location":"reference/configuration/#loggingfile","title":"logging.file","text":"<p>Log file path.</p> Type Default string <code>~/.config/merlya/merlya.log</code> <pre><code>[logging]\nfile = \"~/.config/merlya/merlya.log\"\n</code></pre>"},{"location":"reference/configuration/#loggingmax_size","title":"logging.max_size","text":"<p>Maximum log file size in MB before rotation.</p> Type Default integer <code>10</code> <pre><code>[logging]\nmax_size = 10\n</code></pre>"},{"location":"reference/configuration/#hosts-configuration","title":"Hosts Configuration","text":"<p>Define hosts in <code>~/.config/merlya/hosts.toml</code>:</p> <pre><code># Individual host\n[hosts.web-01]\nhostname = \"web-01.example.com\"\nuser = \"deploy\"\nport = 22\nkey = \"~/.ssh/deploy_key\"\n\n# Host with jump host\n[hosts.internal-db]\nhostname = \"10.0.1.50\"\nuser = \"dbadmin\"\njump_host = \"bastion.example.com\"\n\n# Host group\n[groups.web-tier]\nhosts = [\"web-01\", \"web-02\", \"web-03\"]\ndescription = \"Web server tier\"\n\n[groups.databases]\nhosts = [\"db-master\", \"db-replica-01\"]\ndescription = \"Database tier\"\n</code></pre>"},{"location":"reference/configuration/#host-options","title":"Host Options","text":"Option Type Required Description <code>hostname</code> string Yes Server hostname or IP <code>user</code> string No SSH username <code>port</code> integer No SSH port (default: 22) <code>key</code> string No SSH private key path <code>jump_host</code> string No Jump/bastion host name <code>tags</code> array No Tags for filtering"},{"location":"reference/configuration/#complete-example","title":"Complete Example","text":"<pre><code># ~/.config/merlya/config.toml\n\n[llm]\nprovider = \"openai\"\nmodel = \"gpt-4o-mini\"\ntemperature = 0.7\nmax_tokens = 4096\n\n[ssh]\ntimeout = 30\nmax_connections = 10\nretry_attempts = 3\nretry_delay = 5\ndefault_key = \"~/.ssh/id_ed25519\"\n\n[logging]\nlevel = \"INFO\"\nfile = \"~/.config/merlya/merlya.log\"\nmax_size = 10\n</code></pre>"}]}